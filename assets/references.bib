
@article{lyu_operational_2025,
	title = {Operational modal analysis of a rotating structure in an outdoor environment using a novel image-based long-range tracking continuously scanning laser {Doppler} vibrometer},
	volume = {253},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0263224125006967},
	doi = {10.1016/j.measurement.2025.117337},
	journal = {Measurement},
	author = {Lyu, Linfeng and Zhu, Weidong},
	month = sep,
	year = {2025},
	pages = {117337},
}

@article{poiesi_learning_2021,
	title = {Learning general and distinctive {3D} local deep descriptors for point cloud registration},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2105.10382},
	doi = {10.48550/ARXIV.2105.10382},
	abstract = {An effective 3D descriptor should be invariant to different geometric transformations, such as scale and rotation, robust to occlusions and clutter, and capable of generalising to different application domains. We present a simple yet effective method to learn general and distinctive 3D local descriptors that can be used to register point clouds that are captured in different domains. Point cloud patches are extracted, canonicalised with respect to their local reference frame, and encoded into scale and rotation-invariant compact descriptors by a deep neural network that is invariant to permutations of the input points. This design is what enables our descriptors to generalise across domains. We evaluate and compare our descriptors with alternative handcrafted and deep learning-based descriptors on several indoor and outdoor datasets that are reconstructed by using both RGBD sensors and laser scanners. Our descriptors outperform most recent descriptors by a large margin in terms of generalisation, and also become the state of the art in benchmarks where training and testing are performed in the same domain.},
	author = {Poiesi, Fabio and Boscaini, Davide},
	year = {2021},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, Robotics (cs.RO)},
}

@misc{poiesi_distinctive_2020,
	title = {Distinctive {3D} local deep descriptors},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2009.00258},
	doi = {10.48550/ARXIV.2009.00258},
	publisher = {arXiv},
	author = {Poiesi, Fabio and Boscaini, Davide},
	year = {2020},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
}

@misc{zeng_3dmatch_2016,
	title = {{3DMatch}: {Learning} {Local} {Geometric} {Descriptors} from {RGB}-{D} {Reconstructions}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {{3DMatch}},
	url = {https://arxiv.org/abs/1603.08182},
	doi = {10.48550/ARXIV.1603.08182},
	abstract = {Matching local geometric features on real-world depth images is a challenging task due to the noisy, low-resolution, and incomplete nature of 3D scan data. These difficulties limit the performance of current state-of-art methods, which are typically based on histograms over geometric properties. In this paper, we present 3DMatch, a data-driven model that learns a local volumetric patch descriptor for establishing correspondences between partial 3D data. To amass training data for our model, we propose a self-supervised feature learning method that leverages the millions of correspondence labels found in existing RGB-D reconstructions. Experiments show that our descriptor is not only able to match local geometry in new scenes for reconstruction, but also generalize to different tasks and spatial scales (e.g. instance-level object model alignment for the Amazon Picking Challenge, and mesh surface correspondence). Results show that 3DMatch consistently outperforms other state-of-the-art approaches by a significant margin. Code, data, benchmarks, and pre-trained models are available online at http://3dmatch.cs.princeton.edu},
	publisher = {arXiv},
	author = {Zeng, Andy and Song, Shuran and Nießner, Matthias and Fisher, Matthew and Xiao, Jianxiong and Funkhouser, Thomas},
	year = {2016},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, I.4.7; I.4.5; I.3.5; I.2.10; I.2.6},
}

@misc{qin_geotransformer_2023,
	title = {{GeoTransformer}: {Fast} and {Robust} {Point} {Cloud} {Registration} with {Geometric} {Transformer}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {{GeoTransformer}},
	url = {https://arxiv.org/abs/2308.03768},
	doi = {10.48550/ARXIV.2308.03768},
	abstract = {We study the problem of extracting accurate correspondences for point cloud registration. Recent keypoint-free methods have shown great potential through bypassing the detection of repeatable keypoints which is difficult to do especially in low-overlap scenarios. They seek correspondences over downsampled superpoints, which are then propagated to dense points. Superpoints are matched based on whether their neighboring patches overlap. Such sparse and loose matching requires contextual features capturing the geometric structure of the point clouds. We propose Geometric Transformer, or GeoTransformer for short, to learn geometric feature for robust superpoint matching. It encodes pair-wise distances and triplet-wise angles, making it invariant to rigid transformation and robust in low-overlap cases. The simplistic design attains surprisingly high matching accuracy such that no RANSAC is required in the estimation of alignment transformation, leading to \$100\$ times acceleration. Extensive experiments on rich benchmarks encompassing indoor, outdoor, synthetic, multiway and non-rigid demonstrate the efficacy of GeoTransformer. Notably, our method improves the inlier ratio by \$18\{{\textbackslash}sim\}31\$ percentage points and the registration recall by over \$7\$ points on the challenging 3DLoMatch benchmark. Our code and models are available at {\textbackslash}url\{https://github.com/qinzheng93/GeoTransformer\}.},
	publisher = {arXiv},
	author = {Qin, Zheng and Yu, Hao and Wang, Changjian and Guo, Yulan and Peng, Yuxing and Ilic, Slobodan and Hu, Dewen and Xu, Kai},
	year = {2023},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
}

@inproceedings{choy_fully_2019,
	address = {Seoul, Korea (South)},
	title = {Fully {Convolutional} {Geometric} {Features}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	url = {https://ieeexplore.ieee.org/document/9009829/},
	doi = {10.1109/ICCV.2019.00905},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Choy, Christopher and Park, Jaesik and Koltun, Vladlen},
	month = oct,
	year = {2019},
	pages = {8957--8965},
}

@misc{wang_deep_2019,
	title = {Deep {Closest} {Point}: {Learning} {Representations} for {Point} {Cloud} {Registration}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {Deep {Closest} {Point}},
	url = {https://arxiv.org/abs/1905.03304},
	doi = {10.48550/ARXIV.1905.03304},
	abstract = {Point cloud registration is a key problem for computer vision applied to robotics, medical imaging, and other applications. This problem involves finding a rigid transformation from one point cloud into another so that they align. Iterative Closest Point (ICP) and its variants provide simple and easily-implemented iterative methods for this task, but these algorithms can converge to spurious local optima. To address local optima and other difficulties in the ICP pipeline, we propose a learning-based method, titled Deep Closest Point (DCP), inspired by recent techniques in computer vision and natural language processing. Our model consists of three parts: a point cloud embedding network, an attention-based module combined with a pointer generation layer, to approximate combinatorial matching, and a differentiable singular value decomposition (SVD) layer to extract the final rigid transformation. We train our model end-to-end on the ModelNet40 dataset and show in several settings that it performs better than ICP, its variants (e.g., Go-ICP, FGR), and the recently-proposed learning-based method PointNetLK. Beyond providing a state-of-the-art registration technique, we evaluate the suitability of our learned features transferred to unseen objects. We also provide preliminary analysis of our learned model to help understand whether domain-specific and/or global features facilitate rigid registration.},
	publisher = {arXiv},
	author = {Wang, Yue and Solomon, Justin M.},
	year = {2019},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
}

@inproceedings{rusinkiewicz_efficient_2001,
	address = {Quebec City, Que., Canada},
	title = {Efficient variants of the {ICP} algorithm},
	url = {http://ieeexplore.ieee.org/document/924423/},
	doi = {10.1109/IM.2001.924423},
	booktitle = {Proceedings {Third} {International} {Conference} on 3-{D} {Digital} {Imaging} and {Modeling}},
	publisher = {IEEE Comput. Soc},
	author = {Rusinkiewicz, S. and Levoy, M.},
	year = {2001},
	pages = {145--152},
}

@inproceedings{rusu_fast_2009,
	title = {Fast {Point} {Feature} {Histograms} ({FPFH}) for {3D} registration},
	doi = {10.1109/ROBOT.2009.5152473},
	booktitle = {2009 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Rusu, Radu Bogdan and Blodow, Nico and Beetz, Michael},
	year = {2009},
	keywords = {Clouds, Computational complexity, Convergence, Histograms, Intelligent systems, Iterative closest point algorithm, Optimization methods, Performance analysis, Robotics and automation, Robustness},
	pages = {3212--3217},
}

@article{bojanic_addressing_2024,
	title = {Addressing the generalization of {3D} registration methods with a featureless baseline and an unbiased benchmark},
	volume = {35},
	url = {https://link.springer.com/10.1007/s00138-024-01510-w},
	doi = {10.1007/s00138-024-01510-w},
	abstract = {Abstract 
            Recent 3D registration methods are mostly learning-based that either find correspondences in feature space and match them, or directly estimate the registration transformation from the given point cloud features. Therefore, these feature-based methods have difficulties with generalizing onto point clouds that differ substantially from their training data. This issue is not so apparent because of the problematic benchmark definitions that cannot provide any in-depth analysis and contain a bias toward similar data. Therefore, we propose a methodology to create a 3D registration benchmark, given a point cloud dataset, that provides a more informative evaluation of a method w.r.t. other benchmarks. Using this methodology, we create a novel FAUST-partial (FP) benchmark, based on the FAUST dataset, with several difficulty levels. The FP benchmark addresses the limitations of the current benchmarks: lack of data and parameter range variability, and allows to evaluate the strengths and weaknesses of a 3D registration method w.r.t. a single registration parameter. Using the new FP benchmark, we provide a thorough analysis of the current state-of-the-art methods and observe that the current method still struggle to generalize onto severely different out-of-sample data. Therefore, we propose a simple featureless traditional 3D registration baseline method based on the weighted cross-correlation between two given point clouds. Our method achieves strong results on current benchmarking datasets, outperforming most deep learning methods. Our source code is available on github.com/DavidBoja/exhaustive-grid-search.},
	number = {3},
	journal = {Machine Vision and Applications},
	author = {Bojanić, David and Bartol, Kristijan and Forest, Josep and Petković, Tomislav and Pribanić, Tomislav},
	month = may,
	year = {2024},
	pages = {41},
}

@article{salti_shot_2014,
	title = {{SHOT}: {Unique} signatures of histograms for surface and texture description},
	volume = {125},
	shorttitle = {{SHOT}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1077314214000988},
	doi = {10.1016/j.cviu.2014.04.011},
	journal = {Computer Vision and Image Understanding},
	author = {Salti, Samuele and Tombari, Federico and Di Stefano, Luigi},
	month = aug,
	year = {2014},
	pages = {251--264},
}

@inproceedings{huang_predator_2021,
	address = {Nashville, TN, USA},
	title = {{PREDATOR}: {Registration} of {3D} {Point} {Clouds} with {Low} {Overlap}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	shorttitle = {{PREDATOR}},
	url = {https://ieeexplore.ieee.org/document/9577334/},
	doi = {10.1109/CVPR46437.2021.00425},
	booktitle = {2021 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Huang, Shengyu and Gojcic, Zan and Usvyatsov, Mikhail and Wieser, Andreas and Schindler, Konrad},
	month = jun,
	year = {2021},
	pages = {4265--4274},
}

@article{ehrhardt_full-field_2017,
	title = {Full-field linear and nonlinear measurements using {Continuous}-{Scan} {Laser} {Doppler} {Vibrometry} and high speed {Three}-{Dimensional} {Digital} {Image} {Correlation}},
	volume = {86},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S088832701500552X},
	doi = {10.1016/j.ymssp.2015.12.003},
	journal = {Mechanical Systems and Signal Processing},
	author = {Ehrhardt, David A. and Allen, Matthew S. and Yang, Shifei and Beberniss, Timothy J.},
	month = mar,
	year = {2017},
	pages = {82--97},
}

@article{yuan_novel_2024,
	title = {A novel mirror-assisted method for full-field vibration measurement of a hollow cylinder using a three-dimensional continuously scanning laser {Doppler} vibrometer system},
	volume = {216},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0888327024003261},
	doi = {10.1016/j.ymssp.2024.111428},
	journal = {Mechanical Systems and Signal Processing},
	author = {Yuan, K. and Zhu, W.D.},
	month = jul,
	year = {2024},
	pages = {111428},
}

@article{franck_robotergestutzte_2023,
	title = {Robotergestützte {3D}-{Laser}-{Doppler}-{Vibrometrie} zur experimentellen {Modalanalyse} von elektrischen {Maschinen}},
	volume = {140},
	url = {https://link.springer.com/10.1007/s00502-023-01126-4},
	doi = {10.1007/s00502-023-01126-4},
	number = {2},
	journal = {e \& i Elektrotechnik und Informationstechnik},
	author = {Franck, Marius and Berft, Dennis and Hameyer, Kay},
	month = apr,
	year = {2023},
	pages = {281--289},
}

@incollection{zhu_continuously_2025,
	title = {Continuously {Scanning} {Laser} {Doppler} {Vibrometry} for {Vibration} {Measurement}: {A} {Tutorial} on {Principles}, {Recent} {Developments}, and {Applications}},
	shorttitle = {Continuously {Scanning} {Laser} {Doppler} {Vibrometry} for {Vibration} {Measurement}},
	url = {https://link.springer.com/10.1007/978-3-031-68192-9_2},
	booktitle = {Computer {Vision} \& {Laser} {Vibrometry}, {Vol}. 6},
	publisher = {Springer Nature Switzerland},
	author = {Zhu, Weidong},
	year = {2025},
	doi = {10.1007/978-3-031-68192-9_2},
	pages = {9--12},
}

@incollection{javh_full-field_2019,
	title = {Full-{Field} {Modal} {Analysis} {Using} a {DSLR} {Camera}},
	url = {http://link.springer.com/10.1007/978-3-319-74476-6_4},
	booktitle = {Structural {Health} {Monitoring}, {Photogrammetry} \& {DIC}, {Volume} 6},
	publisher = {Springer International Publishing},
	author = {Javh, Jaka and Slavič, Janko and Boltežar, Miha},
	year = {2019},
	doi = {10.1007/978-3-319-74476-6_4},
	pages = {27--30},
}

@article{di_maio_continuous_2021,
	title = {Continuous {Scanning} {Laser} {Vibrometry}: {A} raison d’être and applications to vibration measurements},
	volume = {156},
	shorttitle = {Continuous {Scanning} {Laser} {Vibrometry}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0888327020309596},
	doi = {10.1016/j.ymssp.2020.107573},
	abstract = {Continuous Scanning Laser Doppler Vibrometry (CSLDV) methods ﬁrst appeared in the literature in the early 1990s and over the past three decades they have undergone an evolution in terms of procedures and applications which constitute a new state-of-the-art now described in this review paper. The advances in vibration measurement performed by Scanning Laser Doppler Vibrometers augmented the capability of measuring vibration data from a grid of a few hundred measurement points to a single scan which traverses and measures at many thousands of points on the same structure. The deﬂection shapes of vibration modes can be created by assembling two pieces of information from a scanning measurement - temporal and spatial - and the more measurement ‘points’, the better the spatial density and resolution of the deﬂection shape(s). The introduction of Continuous Scanning techniques challenged the traditional principle that the number of measurement points deﬁnes the spatial deﬁnition of the deﬂection shape. Thereafter, high deﬁnition deﬂection shapes could be achieved by measuring a single time series from a continuously sweeping trajectory covering the same surface area that would traditionally be covered by a set of ﬁxed-point measurements, each of which spans a range of frequencies. The CSLDV approach compresses both the temporal oscillation and the spatial distribution of the deﬂection shape into one LDV output-modulated signal, whereby the harmonic oscillation and the spatial distribution across a swept area were now deﬁned by a central response harmonic and its sidebands. This change of perspective in vibration measurements from the conventional stepped-scan method to the continuous-scan approach allowed several researchers to exploit and expand the potential of the scanning vibrometer further than its initial design speciﬁcations. This paper starts with the raison d’être, with a brief historical account of how vibration measurements have developed over the past decades, and then moves to the theoretical background and applications of the CSLDV approach. Finally, the paper presents a philosophical and technical account of the research work carried out by several colleagues over the past thirty years and aims to provide a chronological order to the various advancements that CSLDV techniques offer in engineering structural dynamics. Ó 2021 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).},
	journal = {Mechanical Systems and Signal Processing},
	author = {Di Maio, D. and Castellini, P. and Martarelli, M. and Rothberg, S. and Allen, M.S. and Zhu, W.D. and Ewins, D.J.},
	month = jul,
	year = {2021},
	pages = {107573},
}
